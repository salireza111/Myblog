{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Raw soup in a Raw ware","text":""},{"location":"#jul-2025","title":"Jul | 2025","text":"<ul> <li> <p>\ud83c\udfae FileDrop - Thanks to Mindustry</p> <p>Jul 11, 2025</p> <p> More</p> </li> </ul>"},{"location":"#mar-2025","title":"Mar | 2025","text":"<ul> <li> <p>\ud83d\udd2c 5 and 7 zeros</p> <p>Mar 3, 2025</p> <p> More</p> </li> </ul>"},{"location":"#adaptyvbio-egfr-design-competition","title":"AdaptyvBio | EGFR Design Competition","text":"<ul> <li> <p>\ud83d\udcc4 The Question!</p> <p>Jan , 2025</p> <p> More</p> </li> <li> <p>\ud83d\udcc4 The Quest!</p> <p>Jan , 2025</p> <p> More</p> </li> </ul>"},{"location":"#jan-2025","title":"Jan | 2025","text":"<ul> <li> <p>\ud83d\udd2e AR PDB Visualizer</p> <p>Jan 29, 2025</p> <p> More</p> </li> <li> <p>\ud83e\ude91__Relax Bench __</p> <p>Jan 24, 2025</p> <p> More</p> </li> </ul>"},{"location":"#dec-2024","title":"Dec | 2024","text":"<ul> <li> <p>\ud83d\udee0\ufe0f Ramachandran Viewer</p> <p>Dec 09, 2024</p> <p> More</p> </li> </ul>"},{"location":"#nov-2024","title":"Nov | 2024","text":"<ul> <li> <p>\ud83d\udee0\ufe0f Old Fashioned Frankenstein</p> <p>Nov 24, 2024</p> <p> More</p> </li> </ul>"},{"location":"#sep-2024","title":"Sep | 2024","text":"<ul> <li> <p>\ud83d\udee0\ufe0f Frank is Back</p> <p>Sep 13, 2024</p> <p> More</p> </li> </ul>"},{"location":"#jul-2024","title":"Jul | 2024","text":"<ul> <li> <p>\ud83d\udd27 Pictur to PDB</p> <p>Jul 19, 2024</p> <p> More</p> </li> </ul>"},{"location":"#may-2024","title":"May | 2024","text":"<ul> <li> <p>\ud83d\uddde\ufe0f AlphaFold 3, Is it that impressive?</p> <p>May 12, 2024</p> <p> More</p> </li> <li> <p>\ud83d\uddde\ufe0f AlphaFold 3, Docking experiment</p> <p>May 15, 2024</p> <p> More</p> </li> </ul>"},{"location":"#march-2024","title":"March | 2024","text":"<ul> <li> <p>\ud83d\uddde\ufe0f [3.1.13.1]</p> <p>March 01, 2024</p> <p> More</p> </li> <li> <p>\ud83d\uddde\ufe0f Kingdoms of Life</p> <p>March 03, 2024</p> <p> More</p> </li> </ul>"},{"location":"Texts/0/01/","title":"The Question!","text":""},{"location":"Texts/0/01/#jan-salireza-hashemi","title":"Jan | S.Alireza Hashemi","text":"After the first-round results were announced, we met with (@Kave_nasr) to tackle the following question: Could we establish a single metric\u2014or a combination of metrics\u2014that reliably indicates binding confidence among the top-ranked candidates? Drawing on data from the IL-7a case study and all 201 sequences from the first round, we predicted each structure, took the top-ranked (rank 1) model, and then applied the Rosetta Score function and interface-analyzer (as used by Vasquez and Kuhlman) to seek meaningful correlations. (All structures underwent the fast-relax protocol, in parallel with AF2, to gain some computational advantages over AF2 relaxation.) Below are a few of the plots exploring an assumed correlation between iPAE and X, where X includes:  <p>\u2022   Interface energy</p> <p>\u2022   Hbond energy</p> <p>\u2022   Interface SASA</p> <p>\u2022   Number of Interface Residues</p> <p>\u2022   Complexed Energy</p> <p>\u2022   Complexed SASA</p> <p>\u2022   Side_Score</p> <p>\u2022   Hydrophobic Interactions</p> <p>\u2022   Electrostatic_Score</p> <p>\u2022   Fold_Tree</p> <p>\u2022   Rotamers_Score</p> <p>IL7a Case:</p> <pre><code>\u2022   Baker (B/U): 22/10\n\n\u2022   Adaptyv (B/U): 18/14\n</code></pre>"},{"location":"Texts/0/01/#-open-il7a-pdf-in-new-tab","title":"--&gt; \ud83d\udcc4 Open [IL7a] PDF in New Tab","text":"And as the same procedure for the EGFR case:  <p>EGFR (Round1) Case:</p> <pre><code>\u2022   201 Protein:\n\u2022   Expressed: 147\n\u2022   (B/U): 7/147\n</code></pre>"},{"location":"Texts/0/01/#-open-egfr-pdf-in-new-tab","title":"--&gt; \ud83d\udcc4 Open [EGFR] PDF in New Tab","text":""},{"location":"Texts/0/01/#discussion","title":"Discussion","text":"For now, we plan to include other bakers\u2019 work from RFDiffusion and Round 2 of Adaptyv bio, as it helps clarify noise and, importantly, addresses two main points: first, reducing the bias from the large number of successful proteins reported in the RFDiffusion paper, and second, classifying binders by the model or other shared criteria.  For example, if we look at V\u00e1zquez\u2019s work and the recommended filters (ddG &lt; -40 &amp; pAE &lt;10), it does help screen out cases that don\u2019t meet those conditions. However, there are two issues:  <p>\u2022 Although it effectively filters non-binders, it does not reliably confirm binding confidence.</p> <p>\u2022 For semi-natural binders disqualified in Round 1, these filters did not align with the results.</p>   It\u2019s also worth noting that we used highly selective IL-7a data. We are now calculating Round 2 metrics and incorporating more RFDiffusion data to achieve better classification."},{"location":"Texts/0/01/#deviation-from-correlation-observed-in-natural-binders","title":"Deviation from correlation observed in natural binders:","text":""},{"location":"Texts/0/02/","title":"The Quest!","text":""},{"location":"Texts/0/02/#jan-salireza-hashemi","title":"Jan | S.Alireza Hashemi","text":""},{"location":"Texts/0/02/#overview","title":"Overview","text":"One of the things that stands out after the Round 2 results were published is how well the \u201csurgey\u201d tool pairs with the test sequences. This tool shows how ineffective AlphaFold or even ESMFold can be in the case of point mutation predictions. Essentially, the tool mutates one residue at a time to alanine (A) and then predicts the structures of these newly mutated sequences. The results indicate a significant mismatch and highlight the model\u2019s tendency to resist changing the structure.    <p>X-Link -  Colab-Link</p> <p>Resist to changing the structure, 1 - 25 - 50 and 75 mutation which performs on Elian sequence make it </p> <pre><code>   from\n\u2022   SAGQATLDHVKARADKSKTLEELKELRKEAYEDVWKAYMAVVDETEKKIAEAKATGKGDGKKISEEGANALKTLQNTYGSLADIIDEKAKELRAAEEAAK\n   to\n\u2022   AAAAAALAAAAAAAAAAATAEELAAAAAAAYAAAAAAAAAAAAAAAAAAKAAGAAAAAAIAAAAAAAAAAAAAAAAAIAAAAAEAAAAAAAA\n</code></pre> <p>by keeping the same structure (on 25 mutations even confidence is high)</p>"},{"location":"Texts/0/02/#two-key-observations","title":"Two Key Observations","text":"<p>I tried out some Round 1 and Round 2 models with this tool, and two things caught my attention:</p> <ol> <li> <p>Predicting Authenticity and Bias    Can we predict how genuine these structures are, and how biased they might be?</p> </li> <li> <p>Meaningful Correlation    Do we see a meaningful correlation here?</p> </li> </ol>   Answering the second question requires time and effort to evaluate all possibilities. However, in some cases, we observed that structures are more sensitive to mutations. This might suggest that such sequences deviate from the model\u2019s inherent biases. (Perhaps the subset of binders that behave more sensitively in this tool will also prove meaningful.)  Sensevity to mutations on alec1 binder sequence, low confidence at start is questionable."},{"location":"Texts/0/02/#addressing-potential-biases","title":"Addressing Potential Biases","text":"As for the first issue, we have some ideas. Generally, a high-confidence predicted structure is assumed to be correct, and we often rely on confidence metrics to rank it. But the mutation profile suggests there could be biases coming from both the encoders (MPNN) and the structure prediction models (AF2 and ESM), especially in workflows where sequences are refined, partially diffused, or something similar.  We also tested some mutated sequences on ColabFold-MMSeq and ESM-Fold, comparing their performance with the \u201csurgey\u201d analysis tool (without MSA). The result was striking\u201425 residues mutated to alanine.   x.rustamov-m_18_41 and vs elian.elian3 share 83% sequence similarity. Even though most of the mutations are not in the binding site, it is interesting to see that they still do not bind to the target\u2014despite the predicted structure being very similar. This observation highlights how poorly our models can perform during the refining steps.  briannaughton.2_plus_1 sequence as a much bigger structure, struture prediction on 20 mutants profile, A) surgey tool B) AF2(Colab-Fold) C) ESMFold(Colab-Fold)"},{"location":"Texts/0/02/#potential-solutions","title":"Potential Solutions","text":"A potential solution might come from older, physics-based tools\u2014perhaps not for binding but for structure itself. The idea could be as grand as introducing a completely new tool, or as straightforward as using existing tools to evaluate binders before wet-lab tests.  For instance, we can look at the correlation between structure and sequence using physics-based methods. One approach is to run Robetta domain-based predictions and compare them to AF2 predictions to see how much bias might be affecting the predicted model. We could also consider implementing a PyRosetta model with the surgey tool to assess structure accuracy. In principle, we can evaluate ddG from the sequence and structure separately to see if they are compatible."},{"location":"Texts/0/02/#concluding-thoughts","title":"Concluding Thoughts","text":"Finally, it might be helpful to employ complementary physics-based tools to evaluate the structure on its own. As discussed, the trend of a sequence and its predicted structure should align. There are some well-established tools that predict thermodynamic parameters directly from sequence and structure, showing good efficiency back in the era before ML-based methods.  Now might be the right time to dust off those tools\u2014or even train and fine-tune current models\u2014by incorporating these classical parameters."},{"location":"Texts/11/11/","title":"Picture to PDB","text":""},{"location":"Texts/11/11/#jul-19-2024-salireza-hashemi","title":"Jul 19, 2024 | S.Alireza Hashemi","text":"Somewhere near last week there was an idea based on diffusion models that came to my mind, it is a simple idea but interesting to implant.   Diffusion models are used to produce images and a familiar example for us is DALL-E, then Bakerlab introduces RFDiffusin. Based on a recent idea to produce proteins with Diffusion models and have Rosetta\u2019s main core, they deployed their own network called RFDiffusion. This model tries to learn how proteins fold and then based on three-dimensional geometry try to produce a new one, this new protein could be made from scratch with a great degree of freedom, so it could be useful for designing protein folding and proteins in a de-novo form that not exist in nature yet.  But what is this post about and how it came to my mind?   <p>When I see one of those Alpha-Fold slides that tries to write \u201cAlphaFold\u201d with proteins, I think about a bigger picture and reverse the idea of RFDiffusion; instead of creating proteins based on an image processing network, create pictures with proteins. Simply, try to produce as many folds in a PDB scene, which seems to look like an original picture.</p> <p>But not all you write on a paper is plausible to produce in a single shot try. So right now I am trying to understand PDB files by writing on them and as a simple act, this code transforms pictures to PDB scenarios. </p> As always, Try to transform RNR(5xgu) image to a PDB Scene"},{"location":"Texts/11/11/#availability","title":"Availability","text":"<p>Check out my Github to run it locally:  Link</p> <p>Also you can try it from googlecolab:  Link</p>"},{"location":"Texts/13/13/","title":"Frank in back !","text":""},{"location":"Texts/13/13/#sep-13-2024-salireza-hashemi","title":"Sep 13, 2024 | S.Alireza Hashemi","text":"The main reason behind most inventions, especially FPLC and its components, is to make our lives easier. And by \"us,\" I mean specialists like myself, whose main or side quest is purifying proteins. When you have a tool like this, it\u2019s like holding a gift\u2014sweet freedom in your hands. But when it\u2019s taken away, suddenly, life becomes more complicated than it has any right to be.  Take the Fraction Collector, for example. Last year, when we added it to our FPLC, it revolutionized our workflow. We got comfortable\u2014maybe too comfortable. But then, disaster struck. The old man from the '90s decided to retire early and crashed. Cue the nightmare. With no official office or technician for support, the machine just sat there, collecting more dust than fractions.  But, in the midst of this chaos, curiosity bubbled up inside me like an uncontrollable fire. So, I did what any determined protein enthusiast would do\u2014I cracked it open to see if I could bring it back to life.  <p>HERE IT IS - guys, this is Frank (Frac-950) from inside: </p> <p> </p> <p></p> <p>And this is Frank after surgery:</p> <p></p>"},{"location":"Texts/17/17/","title":"Old Fashioned Frankenstein \ud83d\udee0\ufe0f","text":""},{"location":"Texts/17/17/#nov-24-2024-salireza-hashemi","title":"Nov 24, 2024 | S.Alireza Hashemi","text":"Almost a year ago, after nearly finishing my project on purifying and developing methods to evaluate RNase R (RNR), a challenge stayed on my mind: Besides digesting RNA from the 3\u2019 end, this exonuclease can also act like a helicase, unwinding double-stranded RNA. In this process, RNA enters through a channel, a wedge domain separates the two strands, one strand's 3\u2019 end enters the catalytic site, and the other strand exits through another channel. So, we now know that RNR needs two main channels: one for the substrate to enter and another to guide the 5\u2019 end out. The unsolved question is the role of each channel\u2014identifying which is for substrate entry and which serves as the outlet duct, which is unsolved by now. Dedicated to solving this, I dive deep into the problem using a method that, looking back, seems quite naive. I tried designing mini binders to block each channel, hoping to see if blocking one would deactivate the enzyme on single or double-stranded RNA. The ultimate goal was to create a mini-binder cocktail capable of inhibiting all kinds of nucleases.    Among the excitement around the early introduction of RFDiffusion, I rolled up my sleeves and began designing using the Colab version. After designing, validating, and closely inspecting these proteins\u2014with limited knowledge about proteins and protein design tools\u2014I moved on to docking them together. Using H-dock and HADDOCK for local and global docking revealed a conflict: the peptides could occupy both sites at the same time with significant scores. Meanwhile, eager to understand proteins better, I started a new journey. I decided to pursue a master's in biophysics, and within a year, I immersed myself in protein design literature, focusing especially on the works from the Baker Lab. Then, at just the right time, Adaptyv Bio (Round 1) was announced. Amid the confusion of various methods and tools, this challenge was exactly what I needed to refine my skills. The first two weeks of the month-long opportunity were spent setting up and downloading tools. If that sounds excessive, consider this daily reality: a combination of sanctions, internal bans, and extremely slow internet speeds.   Internet Speed and Difficulty of access to some main packages, drivers, and libraries    After that, I tried to replicate Susana Vazquez's pipeline and explored Longxing Cao's work, who had worked on EGFR before. At this point, I followed some ideas to achieve the lowest possible iPAE on AF2, and after about two weeks, some promising mini peptides appeared on my screen. Despite good iPAE scores, I guessed that these peptides might not be ideal without a scaffold, and keeping their original shapes could be doubtful. To address this, an idea came to me in the final hour before the deadline: stitching sequences together. Inspired by Kuhlman\u2019s work on EvoPro, which created a pool of sequences using crossover ideas, I stitched two of my best peptides with TGF. I looked at the TGF and all my designs to find the best point to break the TGF loop and attach the peptide.    But since this was a last-minute idea, I didn't have the chance to test them or check if the spacing was good enough, so I took a leap of faith, sacrificing two peptides to see the result of the stitching method. After finishing this competition, it was time to prepare for the next one: BioML. Using the same approach, we aimed to design nearly 380 out of 500\u2014the set goal. However, computational limitations prevented us from diving as deep as we wanted, especially in the quality control and filtering parts. A month later, after having zero successful binding attempts in the first round, the bell rang for the next round of Adaptyv Bio. This time, the focus shifted from just designing good computational proteins to understanding why we didn't have a binder and learning from it. I examined 200 designs from the first round and also validated IL-7Ra in Adaptyv Bio, analyzing it with Rosetta as a physics-based tool and other possible data-driven methods. This data was applied in the filtering step, and since the main workflow wasn't set to get the best metrics for the competition, our ranking this time was far from our best in the first round.   CPU cooked with 90\u00b0C package Temp, and 122GB Swap memory from SSD to keep things up    This journey allowed me to follow my passion and attempt to design a protein with a real chance of yielding results in the real world. I'm grateful for the last four months of designing and the year spent studying proteins and protein design tools.  As for my setup and conditions\u2014if it looks messy, it's because I had to add two fans during the competitions (CPU temperatures reached 90\u00b0C during the relaxation step), replace the CPU fan, and keep adding storage drives. Each addition came monthly as I budgeted for the next upgrade. :)   Old Fashioned Frankenstein \ud83d\udee0\ufe0f, 2005 chassis as a body, equipped with a second-hand RTX 3060, with the help of 12100f as a brain. Followed by a lot of fans to keep it not quiet but viable   This mini-monster has housed a range of drives, from an old 2004 Western Digital 256 GB HDD to a modern 2 TB SSD, As a monthly budget system \ud83d\udcbe"},{"location":"Texts/19/19/","title":"Ramachandran Viewer","text":""},{"location":"Texts/19/19/#dec-09-2024-salireza-hashemi","title":"Dec 09, 2024 | S.Alireza Hashemi","text":"<p>Github: Link</p>   Dash-based interactive and dynamic Ramachandran plot viewer with the ability to map the plot on a 3d representation of a PDB file.  * Denoted structures extracted from PDB file, de novo models could act tricky due to the lack of the proper annotation; this could be fixed through the DSSP implementation.  <p></p> <p>Installation guide:</p> <pre><code># Git clone\ngit clone https://github.com/salireza111/-Ramachandran-Viewer.git\n\n# Create the virtual environment\npython -m venv rama-env\n\n# Activate the environment\nsource rama-env/bin/activate  # On macOS/Linux\nrama-env\\Scripts\\activate     # On Windows\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run the code\npython main.py\n</code></pre> <p>and it will be accessible via http://127.0.0.1:8050/ on your browser.</p>"},{"location":"Texts/2/2/","title":"[3.1.13.1]","text":""},{"location":"Texts/2/2/#march-01-2024-salireza-hashemi","title":"March 01, 2024 | S.Alireza Hashemi","text":"RNR, acting as a master sculptor of RNA, \"unwind\" a new vision for me. Just looks like what it does to an RNA.  Two years ago, on a day like today, I found myself, a curious traveler, embarking on a new and magical world of science. Now, looking back at the whole picture of these two years, I see RNR as a magical word that entered me and made my entire journey.  As a newbie! in the field of research and science and as a third-year Bachelor's student, at then I couldn't even imagine such an opportunity to find all those magnificent people and fellow travelers on this path.  RNR (one of those enzymes that act as an exoribonuclease) formed a new vision for me. And now just before saying goodbye to him, I want to start my blog to write about all of those lessons and thoughts.  Hopefully, this is helpful to someone out there!"},{"location":"Texts/23/23/","title":"Relax-Bench \ud83e\ude91","text":""},{"location":"Texts/23/23/#jan-24-2025-salireza-hashemi","title":"Jan 24, 2025 | S.Alireza Hashemi","text":"<p>Github: Link</p> <p></p>   Have you ever dreamed of a wonderland where computer geeks use bio-based problems to assess their new hardware? For instance, they use Relax-Bench instead of Cinebench. So, I made one for my imaginary world, Relax-Bench: A bio-based hardware benchmark tool that can score your CPU based on the pyRosetta relaxation platform, a combination of time and effectiveness to calculate and relax a single protein (obviously for version 1 :)     This tool was developed based on pyrosetta relaxation combined with a handmade PDB visualizer to make it a little more visually appealing and the power to see each of the relaxed trajectories."},{"location":"Texts/23/23/#1-set-the-scene-2-hit-the-start-button-3-wait-till-see-the-result","title":"1- Set the scene  \u2003 \u2003  \u2003 \u2003        2- Hit the start button  \u2003 \u2003 \u2003 \u2003 3- Wait till see the result","text":""},{"location":"Texts/23/23/#compare-your-cpu","title":"Compare your CPU","text":"CPU Score Time <code>M1</code> 29624 169sec <code>12100F</code> 27085 262sec <code>Your CPU :)</code> Submit it"},{"location":"Texts/23/23/#a-little-into-it","title":"A little into it","text":""},{"location":"Texts/23/23/#basics-for-visualisation","title":"Basics for visualisation","text":"<pre><code>WIDTH, HEIGHT = 1280, 720\nFONT_SIZE = 18\nCOLORS = {\n    'background': (30, 30, 30),\n    'button': (50, 200, 50),\n    'hover': (70, 220, 70),\n    'text': (255, 255, 255),\n    'backbone': (200, 25, 25),      \n    'other_atoms': (100, 100, 255),   \n    'bond': (10, 10, 10),             \n    'panel_bg': (40, 40, 40),\n    'panel_border': (200, 200, 200),\n    'button_border': (180, 180, 180),\n    'gradient_start': (50, 50, 50),\n    'gradient_end': (100, 100, 100),\n    'button_highlight': (100, 250, 100),\n}\n</code></pre>"},{"location":"Texts/23/23/#feel-free-to-remove-barriers-to-how-much-you-can-zoom-in","title":"Feel free to remove barriers to how much you can zoom in","text":"<pre><code>class PDBViewer:\n\n...\n\n self.view = {\n            'angle_x': 0,\n            'angle_y': 0,\n            'distance': 300,\n            'fov': 1000,\n            'dragging': False\n        }\n</code></pre>"},{"location":"Texts/23/23/#and-here-you-have-the-ability-to-change-the-relaxation-setup-by-minimizing-the-iteration-you-can-watch-the-atomic-wobbeling-with-more-details","title":"And here you have the ability to change the relaxation setup, by minimizing the iteration you can watch the atomic wobbeling with more details","text":"<pre><code>class RelaxationController:\n\n...\n\n   def run_relaxation(self): \n        start_time = time.time()\n        start_mem = psutil.Process().memory_info().rss\n\n        scorefxn = get_fa_scorefxn()\n        mm = MoveMap()\n        mm.set_bb(True)\n        mm.set_chi(True)\n\n        min_mover = MinMover()\n        min_mover.movemap(mm)\n        min_mover.score_function(scorefxn)\n        min_mover.max_iter(8)\n\n        energy_initial = scorefxn.score(self.pose)\n\n        for loop in range(120):  \n            if not self.running:\n                break\n\n            iter_start = time.time()\n            min_mover.apply(self.pose)\n\n            energy_current = scorefxn.score(self.pose)\n\n            if self.check_convergence(energy_initial, energy_current, energy_threshold=0.1):\n                print(f\"Relaxation stopped at loop {loop} due to minimal energy change.\")\n                break  \n\n            energy_initial = energy_current  \n</code></pre>"},{"location":"Texts/23/23/#and-change-the-path-for-your-designated-pdb","title":"And change the path for your designated PDB","text":"<pre><code>if __name__ == \"__main__\":\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n    viewer = PDBViewer(script_dir + \"/RNR.pdb\")  \n    viewer.run()\n</code></pre> <p>Warning</p> <p>Note that by changing the iteration, loop, and PDB, the score function is not reliable anymore</p>"},{"location":"Texts/23/23/#installation-guide","title":"Installation guide:","text":"<pre><code># Git clone\ngit clone https://github.com/salireza111/Relax_bench.git\n\n# Create the virtual env (you need cond)\nconda env create -f environment.yml\n\n# Activate the environment\nconda activate bioenv\n\n# Run the code\npython main.py\n</code></pre>"},{"location":"Texts/29/29/","title":"\ud83d\udd2e AR PDB Visualizer","text":""},{"location":"Texts/29/29/#jan-29-2025-salireza-hashemi","title":"Jan 29, 2025 | S.Alireza Hashemi","text":"<p>Github: Link</p>   Ever dreamed of touching your protein? Now you can\u2014virtually\u2014with AR_PDB Viewer!  <p></p>"},{"location":"Texts/29/29/#change-the-path-for-your-designated-pdb","title":"Change the path for your designated PDB","text":"<pre><code>if __name__ == \"__main__\":\n    if len(sys.argv) &gt; 1:\n        pdb_path = sys.argv[1]\n    else:\n        script_dir = os.path.dirname(os.path.abspath(__file__))\n        pdb_path = script_dir + \"/RNR.pdb\" #Place your path here\n</code></pre>"},{"location":"Texts/29/29/#installation-guide","title":"Installation guide:","text":"<pre><code># Git clone\ngit clone https://github.com/salireza111/AR_PDB_Visualizer.git\ncd AR_PDB_Visualizer\n\n# Create the virtual env \npython3 -m venv venv\n\n# Activate the environment\nsource venv/bin/activate  # macOS/Linux\nvenv\\Scripts\\activate  # Windows\n\n# Install dependencies\npip install -r requirements.txt\n\n# Run the code\npython main.py\n</code></pre>"},{"location":"Texts/3/3/","title":"Kingdoms of Life","text":""},{"location":"Texts/3/3/#march-03-2024-salireza-hashemi","title":"March 03, 2024 | S.Alireza Hashemi","text":"Have you ever focused on an eye-catching phenomenon in nature? What makes it so special to survive out there?   Based on the book \"Linchpin\" by Seth Godin, in a complex and merciless nature, the one who has an outstanding ability could keep on track; I ask myself every time I face a new opportunity, is there anyone else out there who could do that instead of me? And what is the advantage of me standing there?  RNase R is a conserved enzyme in Kingdoms of Life, but what makes it a linchpin to survive there? In a massive amount of mutations and selections from eternity to eternity. Some other nucleases out there do not make it through evolution, I believe it's just not about the basic ability to be a nuclease, it's all about those traits that play crucial roles in a complex system. The ability to unwind double-stranded RNA, to be a repair man in ribosomal staling, could live in the wild nature of cell cytoplasm as long as the cell needs it and the ability to adapt in different situations when a cell needs it or not.   What is it all about? Who made this great organization out there? And how amazing is it, to organize such a massive, unpredictable atomic puzzle to form the meaning of Life."},{"location":"Texts/31/31/","title":"5 and 7 zeros","text":""},{"location":"Texts/31/31/#mar-3-2025-salireza-hashemi","title":"Mar 3, 2025 | S.Alireza Hashemi","text":"Just before entering the quarter-century club and turning 25 \ud83e\udd73, a friend surprised me with an awesome gift:   \u2003A 3D-printed version of RNR, a model that\u2019s 5*10<sup>7</sup> times bigger (1nm:5cm)!"},{"location":"Texts/31/31/#ps-ive-never-felt-or-seen-anything-like-this-beforediscovering-how-incredible-proteins-are-and-realizing-the-tiny-scale-of-life-we-rely-on-is-mind-blowing","title":"P.S. I\u2019ve never felt or seen anything like this before\u2014discovering how incredible proteins are and realizing the tiny scale of life we rely on is mind-blowing.","text":""},{"location":"Texts/31/31/#ps2-we-dont-often-get-the-chance-to-grasp-the-huge-magnificationsmillions-of-timesneeded-just-to-be-able-to-touch-something-this-small-now-all-those-numbers-about-microscopy-finally-make-sense-in-a-whole-new-way","title":"P.S.2 We don\u2019t often get the chance to grasp the huge magnifications\u2014millions of times\u2014needed just to be able to touch something this small. Now all those numbers about microscopy finally make sense in a whole new way.","text":""},{"location":"Texts/31/31/#ps3-feeling-it-with-my-eyes-closed-is-amazing-tooit-makes-me-think-of-an-afm","title":"P.S.3  Feeling it with my eyes closed is amazing too\u2014it makes me think of an AFM :)","text":""},{"location":"Texts/37/37/","title":"FileDrop - Thanks to Mindustry","text":""},{"location":"Texts/37/37/#jul-11-2025-salireza-hashemi","title":"Jul 11, 2025 | S.Alireza Hashemi","text":"<p>\ud83c\udfae Mindustry: Link</p>   For the last holidays I dove back into Mindustry. I\u2019d played solo before, but this time four of us teamed up over a local session\u2014and wow, it was a blast. It still amazes me how they pack so much detail and smooth play into a 70 MB game."},{"location":"Texts/37/37/#cross-platform","title":"Cross-platform? \u2714\ufe0f","text":""},{"location":"Texts/37/37/#free-to-play","title":"Free to play? \u2714\ufe0f","text":""},{"location":"Texts/37/37/#easy-to-set-up","title":"Easy to set up? \u2714\ufe0f","text":"Back at work I wanted to bring our four-day campaign onto my own PC. That meant reinstalling the exact build we\u2019d used, then copying the saves. With my snail internet (see earlier posts) that sounded painful. Then I remembered how easily the game connected over LAN\u2014why not move the files the same way?"},{"location":"Texts/37/37/#manual-sharing-nope","title":"Manual sharing? Nope.","text":""},{"location":"Texts/37/37/#search-around-for-some-tools-also-nope","title":"Search around for some tools? Also Nope.","text":"So I put together a quick transfer app in PyQt. A few prompts to GPT later and it felt good enough to release. Say hello to FileDrop, a small, cross-platform file-sharing toolkit. While building it I tacked on a couple of bonuses: sending short notes (handy for mirroring GPT prompts between two machines) and a one-click option to pull files from an SSH server via SCP\u2014to finally scratching that old itch."},{"location":"Texts/37/37/#github-link","title":"Github: Link","text":""},{"location":"Texts/37/37/#downloads-v1","title":"Downloads (V1)","text":"Platform File Linux FileDrop-linux.tar.gz macOS FileDrop-mac.zip Windows FileDrop-windows.7z"},{"location":"Texts/37/37/#install-on-macos-homebrew","title":"\ud83d\udce6 Install on macOS (Homebrew)","text":"<pre><code># Add the tap once\nbrew tap salireza111/filedrop\n\n# Then install or upgrade any time\nbrew install --cask filedrop\n</code></pre>"},{"location":"Texts/5/5/","title":"AlphaFold 3, Is it that impressive?","text":""},{"location":"Texts/5/5/#may-12-2024-salireza-hashemi","title":"May 12, 2024 | S.Alireza Hashemi","text":"After AlphaFold3 (AF3) just came out last Wednesday, I've run some benchmarks, and to me, the most remarkable aspect of this model has been its significant speed enhancements.  Deepmind has modified the network of AF3 by adhering to AlphaFold2 architecture, while it contains some crucial changes. One of those changes that caught my attention is about how the model will behave with MSA. (Multiple Sequence Alignment)  AF2 has mostly modified the MSA on 48 blocks of Evoformer along with pair representation. While now on AF3 they have reduced this modification to a single-step module (consisting of 4 blocks) before the main module; Pairformer, which is now performing only on pair representation date.  Obviously, generative models have seen impressive development in recent years, this has taken a place as one of the main changes in AF3 architecture. It is replaced with a \"structure module\" in AF2. Based on my own understanding of this step, with the help of diffusion models not only AF3 is now capable of modeling the structures of a variety of other atoms such as ligands within the prediction, but also operates significantly faster than the structure module on AF2.  <p>Please read the unedited version of the AF3 article on Nature to address more details. (Link)</p>   Here are some quick benchmarks: (Please note that I've run these models on Google Colab basic set-up with mostly basic presets of these models, So they may be not accurate for being a reference, by the way, it's cool for me to look at them to see how much they've changed)  I try to predict RNase R structure from E. coli (PDB: 5XGU_ 833 amino_acids) so basically one of the changes I've decided to make in the default presets is to turn on the template modeling, I've done this because I believe that AF3 maybe used template modeling on it, and based on the webserver we have access to it I can't change this option. For this issue, I will run a novel sequence generated with Protein MPNN at the next step to ensure both models AF3 and AF2 equally could perform well on the structures without initial guesses.  <p>Here I present data from four models:</p> <ul> <li>AF3 (1)</li> <li>AFM V2.3 (2)</li> <li>ColabFold AF_Ptm with mmseqs (3)</li> <li>ColabFold Multimer V2.3 with mmseqs (4)</li> </ul> Time to predict structure, Note that installation time on colab is not added to this time. But server setup should be considered. AF3 server not mentioned the setup but all colab predictions run on T4 GPU. predicted template modeling not provided for AFM colab version. Comparison of RNase R (5XGU) with  AlphaFold Rank 1 in compared models It's obvious that those models struggled with both C and N terminals. (Predicted models colored by pLDDT) - Rendered by ChimeraX Comparison of available MSAs It shows that even with the generative step at AF3 this model acts as same as the other one, It actually doesn't hallucinate for terminals in which there isn't as much data available for it, making it suitable for this kind of error. AF3 was trained on Alpha Fold Multime as a solution for hallucination which makes sense in the last figure on the same predication for terminals. <p>Will be updated ...</p> <p>Contact with me on my blog or by salireza111@gmail.com</p> <p>References:</p> <ul> <li>Mirdita M, Sch\u00fctze K, Moriwaki Y, Heo L, Ovchinnikov S and Steinegger M. ColabFold: Making protein folding accessible to all.</li> <li>Nature Methods (2022) doi: 10.1038/s41592-022-01488-1</li> <li>Jumper et al. \"Highly accurate protein structure prediction with AlphaFold.\"</li> <li>Nature (2021) doi: 10.1038/s41586-021-03819-2</li> <li>Evans et al. \"Protein complex prediction with AlphaFold-Multimer.\"</li> <li>biorxiv (2021) doi: 10.1101/2021.10.04.463034v1</li> <li>Minkyung et al. \"Accurate prediction of protein structures and interactions using a three-track neural network.\"</li> <li>Science (2021) doi: 10.1126/science.abj8754</li> <li>Jumper, J., Evans, R., Pritzel, A. et al. Highly accurate protein structure prediction with AlphaFold. Nature 596, 583\u2013589 (2021). https://doi.org/10.1038/s41586-021-03819-2</li> <li>Abramson, J., Adler, J., Dunger, J. et al. Accurate structure prediction of biomolecular interactions with AlphaFold\u20093. Nature (2024). https://doi.org/10.1038/s41586-024-07487-w</li> <li>Graphs Rendered by visme.co</li> </ul>"},{"location":"Texts/7/7/","title":"AlphaFold 3, Docking experiment","text":""},{"location":"Texts/7/7/#may-15-2024-salireza-hashemi","title":"May 15, 2024 | S.Alireza Hashemi","text":"<p>Recently reading an article made me to do an experiment, Bj\u00f6rn Wallner introduced a new model, called \"AFsample\" in one of his latest works[1].</p> <p>In that article, Wallner discusses his 2022 work on designing protein-peptide complexes [2], the potential issues, and their solutions. The main concept behind AFsample is to enhance AlphaFold's accuracy through increased sampling, as getting trapped in local minima could result in thousands of similar structures.</p>   Wallner demonstrates that introducing noise and trying to partially interrupt the network could significantly solve the problem, also he reports a massive advancement in the DockQ score of AFsample comparison to AlphaFold multimer. In this test, he used CASP targets to benchmark these two models.  Among the samples in 8 of the cases, AlphaFold Multimer rank-1 predictions couldn't achieve the minimum score of o.23 in DockQ, whereas AFsample achieved a score greater than 0.4 in 6 of those samples.  I found these results interesting to provide a benchmark for AlphaFold3; here I show the model accuracy of AlphaFold3 compared to AlphaFold Multimer and AFsample on a single Docking situation.  H1129 (PDB: 8A8C) was chosen for this test, for which Wallner reported a DockQ score greater than 0.6 for the AFsample. Also, he noted that AlphaFold Multimer couldn't achieve a minimum score of o.23 for this target.  I've tested AlphaFold3, AlphaFold Multimer, and AFM with \"Template: PDB100\" on this case; Here are the results:  Comparison Ranked 1 prediction of H1129 (PDB: 8A8C) in AlphaFold3 and AlphaFold Multimer v3 (ColabFold) (Predicted models colored by pLDDT) - Rendered by ChimeraX Comparison Ranked 1 prediction of H1129 (PDB: 8A8C) between test models.   For a quick conclusion; this benchmark shows a massive gap between the situation when there is a template available for our model. (78.9 vs 93.4 in pLDDT score and 0.869 vs 0.094 in DockQ score) Also, AlphaFold3 didn't come up well in this benchmark which questioned my last hypothesis about using the template in this model.  <p>Also for calculating pLDDT for AlphaFold3 which is not reported in the AF3 webserver, I've developed this script:</p> <p>https://github.com/salireza111/AlphaFold3_pLDDT</p> <p>Will be updated ...</p> <p>Contact with me on my blog or by salireza111@gmail.com</p> <p>References:</p> <ul> <li>Mirdita M, Sch\u00fctze K, Moriwaki Y, Heo L, Ovchinnikov S and Steinegger M. ColabFold: Making protein folding accessible to all.</li> <li>Nature Methods (2022) doi: 10.1038/s41592-022-01488-1</li> <li>Jumper et al. \"Highly accurate protein structure prediction with AlphaFold.\"</li> <li>Nature (2021) doi: 10.1038/s41586-021-03819-2</li> <li>Evans et al. \"Protein complex prediction with AlphaFold-Multimer.\"</li> <li>biorxiv (2021) doi: 10.1101/2021.10.04.463034v1</li> <li>Minkyung et al. \"Accurate prediction of protein structures and interactions using a three-track neural network.\"</li> <li>Science (2021) doi: 10.1126/science.abj8754</li> <li>Jumper, J., Evans, R., Pritzel, A. et al. Highly accurate protein structure prediction with AlphaFold. Nature 596, 583\u2013589 (2021). https://doi.org/10.1038/s41586-021-03819-2</li> <li>Abramson, J., Adler, J., Dunger, J. et al. Accurate structure prediction of biomolecular interactions with AlphaFold\u20093. Nature (2024). https://doi.org/10.1038/s41586-024-07487-w</li> <li>Graphs Rendered by visme.co</li> <li>Wallner, Bj\u00f6rn. \u201cAFsample: Improving Multimer Prediction with AlphaFold using Aggressive Sampling.\u201d bioRxiv (2023): n. pag.</li> <li>Johansson-\u00c5khe I and Wallner B (2022) Improving peptide-protein docking with AlphaFold-Multimer using forced sampling. Front. Bioinform. 2:959160. doi: 10.3389/fbinf.2022.959160</li> <li>https://github.com/salireza111/AlphaFold3_pLDDT</li> </ul>"}]}